<!DOCTYPE html>
<html>
<head>
<title></title>
<!-- 2017-10-21 Sat 13:58 -->
<meta  charset="utf-8" />
<meta  htto-equiv="X-UA-Compatible" content="chrome=1" />
<meta  name="generator" content="Org-mode with org-ioslide" />
<meta  name="author" content="Raynold Ng" />


<!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--This one seems to work all the time, but really small on ipad-->
<!--<meta name="viewport" content="initial-scale=0.4">-->
<meta name="apple-mobile-web-app-capable" content="yes" />
<link rel="stylesheet" media="all" href="theme/css/default.css" />
<link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css" />
<link rel="stylesheet" media="all" href="theme/css/small-icon.css" />
<base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
<script data-main="js/slides" src="js/require-1.0.8.min.js"></script>

   <script src="js/jquery-1.7.1.min.js" type="text/javascript"></script>

<script src="js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML,local/local" type="text/javascript"></script>
</head>
<body style="opacity: 0">
<slides class="layout-widescreen">
<slide class="title-slide segue nobackground">
       <aside class="gdbar"><img src="images/tensorflow.png"></aside>
       <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
       <hgroup class="auto-fadein">
         <h1 data-config-title><!-- populated from slide_config.json --></h1>
         <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
         <p data-config-presenter><!-- populated from slide_config.json --></p>
       </hgroup>
    </slide>
  <slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org50b0dd9" class="outline-2">
<h2 id="org50b0dd9">Agenda</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Installation and Setup</li>
<li>Machine Learning Primer</li>
<li>What's TensorFlow?</li>
<li>Basic TensorFlow concepts</li>
<li>MNIST Example
<ul>
<li>Softmax</li>
<li>Convoluted Neural Networks</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgab38ce3" class="outline-2">
<h2 id="orgab38ce3">NUS Hackers</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>student-run organization committed to the spread of hacker culture &amp; free/open-source software</li>
<li>Events:
<ul>
<li><a href="https://www.nushackers.org/fridayhacks/">Friday Hacks</a></li>
<li><a href="http://school.nushackers.org/">hackerschool</a></li>
<li><a href="https://www.facebook.com/groups/nushackers/permalink/1186836361416932/">Project Intern</a></li>
</ul></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgf3290a1" class="outline-2">
<h2 id="orgf3290a1">Installation and Setup</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Ensure that you have the following installed:
</p>
<ol>
<li>TensorFlow: <a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a></li>
<li>Python 3: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
<li>Jupyter (recommended): <a href="http://jupyter.org/">http://jupyter.org/</a></li>
</ol>

<p>
Materials are available <a href="https://github.com/raynoldng/hackerschool-tensorflow">here</a>
</p>


</article>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgcaf5502" class="outline-2">
<h2 id="orgcaf5502">Machine Learning Primer</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org93e2410" class="outline-3">
<h3 id="org93e2410">What is Machine Learning?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>"The science of getting computers to act <b>without being explicitly programmed</b>" - Andrew Ng</li>
<li>Primary aim is to allow computers to learn automatically without human
intervention or assistance and adjust actions accordingly</li>
</ul>


<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/machine_learning.png" alt="machine_learning.png" width="40%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga5ae183" class="outline-3">
<h3 id="orga5ae183">Using TensorFlow to sort cucumbers</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><a href="https://cloud.google.com/blog/big-data/2016/08/how-a-japanese-cucumber-farmer-is-using-deep-learning-and-tensorflow">Makoto Koike</a> used deeping learning and TensorFlow to sort cucumbers by size, shape, color and other attributes</li>
</ul>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/cucumber.png" alt="cucumber.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org69d5977" class="outline-3">
<h3 id="org69d5977">Structure in data</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>some interpretations to "structure in data"
<ul>
<li>given some data, one can predict other data points with some confidence</li>
<li>one can compress the data, i.e., store the same amount of information, with
less space</li>
</ul></li>
</ul>

\begin{align*}
A = \{1, 2, 6, 4, 7, 9, 0\} \\
B = \{1, 2, 1, 2, 1, 2, 1\}
\end{align*}

<ul>
<li>we might say that \(A\) has apparent structure while \(B\) does not</li>
</ul>


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0254668" class="outline-4">
<h4 id="org0254668">Entropy</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>quantified as Entropy of Process</li>
</ul>
<p>
\[H(X) = -\sum_{i=1}^{N} p(x_i) \log p(x_i)\]
</p>
<ul>
<li>If entropy increases, uncertainty in prediction increases</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc186094" class="outline-4">
<h4 id="orgc186094">Entropy (examples)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Example: fair dice</li>
</ul>
<p>
\[H(\text{fair dice roll}) = -\sum_{i=1}^6 \frac{1}{6} \log \frac{1}{6}=2.58\]
</p>
<ul>
<li>Example: biased 20:80 coin</li>
</ul>
<p>
\[H(20/80 \text{ coin toss}) = -\frac{1}{5}\log \frac{1}{5}-\frac{4}{5}\log \frac{4}{5} = 0.72\]
</p>
<ul>
<li>biased coin toss has lower entropy; predicting its outcome is easier than a fair dice</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1e6289a" class="outline-3">
<h3 id="org1e6289a">What are Tensors?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Recall from linear algebra that:
</p>
<ul>
<li>Scalar: an array in 0-D</li>
<li>Vector: an array in 1-D</li>
<li>Matrix: an array in 2-D</li>
</ul>

<p>
All are <b>tensors</b> of n-order. Similary, tensors can be transformed with
operations. TensorFlow provides library of algorithms to perform tensor operations efficiently. 
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6f11642" class="outline-3">
<h3 id="org6f11642">Example</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Simple linear regression model:
</p>

<p>
\[w_o + w_1 x = \hat{y}\]
</p>

<ul>
<li>\(w_0\) and \(w_1\) are <b>weights</b>, that are determined during training</li>
<li>\(\hat{y}\) is the predicted outcome, to be compared with actual observations \(y\)</li>
<li>Goal: build a model that can find values of \(w_0\) and \(w_1\) that minimize prediction error</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org95fc7d9" class="outline-3">
<h3 id="org95fc7d9">Graph Representation of ML Models</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Can represent linear regression as a graph
</p>

<div class="figure">
<p><img src="images/linear_reg_graph.png" alt="linear_reg_graph.png" width="40%" />
</p>
</div>

<ul>
<li>operations are represented as nodes</li>
<li>graph shows how data is transformed by nodes and what is passed between them</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org447f619" class="outline-3">
<h3 id="org447f619">Graph Representation of ML Models (1)</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">

<div class="figure">
<p><img src="images/neural_net.png" alt="neural_net.png" width="50%" />
</p>
</div>

<p>
\[a_i^{(2)} = g(w_{i0} + w_{i1}x_1 + w_{i2}x_2 + w_{i3}x_3)\]
</p>

<p>
For more complex models, it could be helpful to visualize your graph.
<a href="https://www.tensorflow.org/versions/r0.7/how_tos/graph_viz/index.html">TensorBoard</a> provides this virtualization tool
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org364eb86" class="outline-3">
<h3 id="org364eb86">Activation Functions</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>A popular function is the rectified linear unit (<b>ReLU</b>):</li>
</ul>
<p>
\[g(u) = max(0, u)\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/relu.png" alt="relu.png" width="70%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org993b011" class="outline-3">
<h3 id="org993b011">Gradient Descent</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>a way to minimize objective function</li>
<li>one takes steps proportional to the negative of the gradient of the function at the current point.</li>
</ul>


<div class="figure">
<p><img src="images/gradient_descent.png" alt="gradient_descent.png" width="50%" />
</p>
</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd2cf759" class="outline-3">
<h3 id="orgd2cf759">Model Output</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>output depends on activation function used, but is generally any real number \([-\infty, \infty]\)</li>
<li>For binary classification, an additional sigmoid function can be applied to
bring the output to range of \([0,1]\)</li>
</ul>
<p>
\[S(x) = \frac{1}{1+e^{-x}}\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sigmoid.png" alt="sigmoid.png" width="90%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdc3dfbc" class="outline-3">
<h3 id="orgdc3dfbc">Softmax Function</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>for multi-class prediction a softmax function is used:</li>
</ul>
<p>
\[S_j(\boldsymbol{z}) = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \text{ for }j=1,\dots,k\]
</p>
<ul>
<li>squash \(K\) dimensional vector <b>z</b> to a \(K\) dimensional vector that sum to 1</li>
</ul>
<p>
\[\sum_{j=1}^k S_j(\boldsymbol{z}) = 1\]
</p>
<ul>
<li>state usually represented with <b>one-hot encoding</b>, e.g for dice roll 3: \((0,0,1,0,0,0)\)</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org1cd829c" class="outline-2">
<h2 id="org1cd829c">Basic TensorFlow Concepts</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga511da0" class="outline-3">
<h3 id="orga511da0">What is TensorFlow?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms"</li>
<li>Originally developed Google Brain Team to conduct machine learning research and deep neural networks research</li>
<li>General enough to be applicable to a wide variety of other domains</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfbd97cc" class="outline-3">
<h3 id="orgfbd97cc">Data Flow Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Tensorflow separates definition of computations from their execution
</p>

<p>
Phases:
</p>
<ol>
<li>assemble the graph</li>
<li>use a <code>session</code> to execute operations in the graph</li>
</ol>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
a = tf.add(3,5)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb7adcca" class="outline-3">
<h3 id="orgb7adcca">How to get value of <code>a</code>?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
print(a)
</pre>

</div>

<p>
Create a <code>session</code>, and within it, evaluate the graph
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
print(sess.run(a))
sess.close()
</pre>

</div>

<p>
Alternatively:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
with tf.Session() as sess:
    print(sess.run(a))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4b6d05a" class="outline-3">
<h3 id="org4b6d05a">Visualizing with TensorBoard</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="smaller" id="text-">
<ul>
<li><code>tf.summary.FileWriter</code> serializes the graph into a format the TensorBoard can read</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
tf.summary.FileWriter("logs", tf.get_default_graph()).close()
</pre>

</div>

<ul>
<li>in the same directory, run:</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="sh">
tensorboard --logdir=logs
</pre>

</div>

<p>
Or in Jupyter:
</p>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
!tensorboard --logdir=logs
</pre>

</div>

<ul>
<li>This will launch an instance of TensorBoard that you can access at <a href="http://localhost:6006">http://localhost:6006</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org47ee58a" class="outline-3">
<h3 id="org47ee58a">Practice with More Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Try to generate the following graph: \((x+y)^{xy}\) where \(x=2,y=3\)
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/graph2.png" alt="graph2.png" width="70%" />
</p>
</div>
</article>

<p>
Useful functions: <code>tf.add</code>, <code>tf.multiply</code>, <code>tf.pow</code>
</p>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd5fb4df" class="outline-3">
<h3 id="orgd5fb4df">Solution</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = 2
y = 3
op1 = tf.add(x, y)
op2 = tf.multiply(x, y)
op3 = tf.pow(op1, op2)
with tf.Session() as sess:
    op3 = sess.run(op3)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge90a098" class="outline-3">
<h3 id="orge90a098">TensorFlow Variables</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>TensorFlow variables used to represent shared, persistant state manipulated by your program</li>
<li>Variables hold and update parameters in your model during training</li>
<li>Variables contain tensors</li>
<li>Variables must be initialized unless it is a constant</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W1 = tf.ones((2,2))
W2 = tf.Variable(tf.zeros((2,2)), name="weights")

with tf.Session() as sess:
    print(sess.run(W1))
    sess.run(tf.global_variables_initializer())
    print(sess.run(W2))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgde00375" class="outline-3">
<h3 id="orgde00375">Creating Variables</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
To create a 3-dimensional variable with shape <code>[1,2,3]</code>:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
my_var = tf.get_variable("my_var", [1,2,3])
</pre>

</div>

<p>
You may optionally specify the <code>dtype</code> and initializer to <code>tf.get_variable</code>:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
my_int_variable = tf.get_variable("my_int_variable", [1, 2, 3],
                                  dtype=tf.int32,
                                  initializer=tf.zeros_initializer)
</pre>

</div>

<p>
Can initialize a <code>tf.Variable</code> to have the value of a <code>tf.Tensor</code>:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
other_variable = tf.get_variable("other_variable", dtype=tf.int32, 
  initializer=tf.constant([23, 42]))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4e90b0c" class="outline-3">
<h3 id="org4e90b0c">Updating Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <code>tf.assign</code> to assign a value to a variable
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
state = tf.Variable(0, name="counter")
new_value = tf.add(state, tf.constant(1))
update = tf.assign(state, new_value)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(state))
    for _ in range(3):
        sess.run(update)
        print(sess.run(state))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3b7cd5a" class="outline-3">
<h3 id="org3b7cd5a">Fetching Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)
intermed = tf.add(input2, input3)
mul = tf.multiply(input1, intermed)

with tf.Session() as sess:
    result = sess.run([mul, intermed])
    print(result)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0d0100e" class="outline-3">
<h3 id="org0d0100e">TensorFlow Placeholders</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.placeholder</code> variables represent our input data</li>
<li><code>feed_dict</code> is a python dictionary that maps <code>tf.placeholder</code> variables to data</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)

output = tf.multiply(input1, input2)

with tf.Session() as sess:
    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org0f54b72" class="outline-3">
<h3 id="org0f54b72">Example: Linear Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org652a807" class="outline-4">
<h4 id="org652a807">Imports</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
import numpy as np
import seaborn
import matplotlib.pyplot as plt
# %matplotlib inline
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3e320a3" class="outline-4">
<h4 id="org3e320a3">Recap</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>we have two weights \(w_0\) and \(w_1\), we want the model to figure out good weights by minimizing prediction error</li>
<li>define the following <b>loss function</b></li>
</ul>

<p>
\[L = \sum (y - \hat{y})^2\]
</p>

<p>
Given the following function, fit a linear model
</p>

<p>
\[y = x + 20 \sin(x/10)\]
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfaeadd4" class="outline-4">
<h4 id="orgfaeadd4">Scatter Plot</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sample_data.png" alt="sample_data.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7a7af6c" class="outline-4">
<h4 id="org7a7af6c">Define Variables and Placeholders</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define data size and batch size
n_samples = 1000
batch_size = 100

# TensorFlow is particular about shapes, so resize
X_data = np.reshape(X_data, (n_samples, 1))
y_data = np.reshape(y_data, (n_samples, 1))

# Define placeholders for input
X = tf.placeholder(tf.float32, shape=(batch_size, 1))
y = tf.placeholder(tf.float32, shape=(batch_size, 1))
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0d4d654" class="outline-4">
<h4 id="org0d4d654">Loss Function</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Loss function is defined as:
\[J(W,b) = \frac{1}{N}\sum_{i=1}^{N}(y_i-(W_{x_i}+b))^2\]
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define variables to be learned
W = tf.get_variable("weights", (1,1),
                    initializer = tf.random_normal_initializer())
b = tf.get_variable("bias", (1,),
                    initializer = tf.constant_initializer(0.0))
y_pred = tf.matmul(X, W) + b
loss = tf.reduce_sum((y - y_pred)**2/n_samples)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge6ce1d3" class="outline-4">
<h4 id="orge6ce1d3">Define Optimizer and Train Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="smaller" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define optimizer operation
opt_operation = tf.train.AdamOptimizer().minimize(loss)
with tf.Session() as sess:
    # Initialize all variables in graph
    sess.run(tf.global_variables_initializer())
    # Gradient descent for 500 steps:
    for _ in range(500):
        # Select from random mini batch
        indices = np.random.choice(n_samples, batch_size)
        X_batch, y_batch = X_data[indices], y_data[indices]
        # Do gradient descent step
        _, loss_val = sess.run([opt_operation, loss],
                               feed_dict={X: X_batch, y: y_batch})
    print(sess.run([W, b]))
    # Display results
    plt.scatter(X_data, y_data)
    plt.scatter(X_data, sess.run(W) * X_data + sess.run(b), c='g')
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org8168e84" class="outline-4">
<h4 id="org8168e84">Results</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/trained_model.png" alt="trained_model.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org97040a1" class="outline-2">
<h2 id="org97040a1">MNIST and TensorFlow</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org864c3e4" class="outline-3">
<h3 id="org864c3e4">Introduction</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>MNIST is the hello world of machine learning</li>
<li>Simple computer vision dataset, consists of images of handwritten digits</li>
<li>We are going to train a model to predict what the digits are</li>
</ul>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/MNIST.png" alt="MNIST.png" width="80%" />
</p>
</div>
</article>


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfa84eef" class="outline-4">
<h4 id="orgfa84eef">Importing MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
To download and read in the data automatically:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
</pre>

</div>

<p>
One hot encoding
</p>
<ul>
<li>labels have been converted to a vector of length equal to number of classes.</li>
<li>the ith element is 1, rest are 0. E.g. Digit 1: \([0,1,\dots]\)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge95d9f6" class="outline-4">
<h4 id="orge95d9f6">MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
The MNIST data is split into three parts:
</p>
<ol>
<li>55,000 data points of training data (<code>mnist.train</code>)</li>
<li>10,000 data points of test data (<code>mnist.test</code>)</li>
<li>5,000 data points of validation data (<code>mnist.validation</code>)</li>
</ol>

<p>
Every MNIST data has 2 parts:
</p>
<ol>
<li>an image of a handwritten digit (call it "x")</li>
<li>corresponding label (call it "y")</li>
</ol>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgc1a841f" class="outline-3">
<h3 id="orgc1a841f">Softmax Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org178bc9c" class="outline-4">
<h4 id="org178bc9c">Overview</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">

<div class="figure">
<p><img src="images/softmax_1.png" alt="softmax_1.png" width="80%" />
</p>
</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6b5a12d" class="outline-4">
<h4 id="org6b5a12d">Overview (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_2.png" alt="softmax_2.png" width="120%" />
</p>
</div>
</article>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_3.png" alt="softmax_3.png" width="120%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdf19d82" class="outline-4">
<h4 id="orgdf19d82">Data Dimensions</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
img_size = 28
img_size_flat = img_size * img_size
img_shape = (img_size, img_size)
num_classes = 10
</pre>

</div>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/mnist_7.png" alt="mnist_7.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org54f51a2" class="outline-4">
<h4 id="org54f51a2">Defining Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = tf.placeholder(tf.float32, [None, img_size_flat])
y_true = tf.placeholder(tf.float32, [None, num_classes])
y_true_cls = tf.placeholder(tf.int64, [None])
</pre>

</div>

<ul>
<li><code>x</code> is a <code>placeholder</code>, value that we will input when we ask TensorFlow to run</li>
<li>represent MNIST image as a 2-D tensor of floating numbers of shape <code>[None, 784]</code></li>
<li><code>None</code> means that <code>x</code> can be of any length</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge4033f1" class="outline-4">
<h4 id="orge4033f1">Variables to be Optimized</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
weights = tf.Variable(tf.zeros([img_size_flat, num_classes]))
biases = tf.Variable(tf.zeros([num_classes]))
</pre>

</div>
<ul>
<li>weights has a shape of <code>[784,10]</code> as we want to 784-dimensional image vectors
by <code>weights</code> to produce 10-dimensional vectors of evidence</li>
<li>biases has a shape of [10] as we can add it to the output.</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgae32db7" class="outline-4">
<h4 id="orgae32db7">Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>multiples the images in the placeholder variable <code>x</code> with <code>weight</code> and <code>biases</code></li>
<li>Result is a matrix of shape <code>[num_images, 10]</code> and <code>W</code> has shape <code>[784, 10]</code>.</li>
<li><code>logits</code> is typical TensorFlow terminology</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
logits = tf.matmul(x, weights) + biases
y_pred = tf.nn.softmax(logits)
y_pred_cls = tf.argmax(y_pred, axis = 1)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb54e759" class="outline-4">
<h4 id="orgb54e759">Optimization Method</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,
                                                        labels=y_true)
cost = tf.reduce_mean(cross_entropy)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfa629fa" class="outline-4">
<h4 id="orgfa629fa">TensorFlow Run</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def optimize(num_iterations):
    for i in range(num_iterations):
        x_batch, y_true_batch = mnist.train.next_batch(batch_size)
        feed_dict_train = {x: x_batch,
                           y_true: y_true_batch}
        session.run(optimizer, feed_dict=feed_dict_train)
</pre>

</div>

<p>
Using small batches of random data is called <b>stochastic training</b>, it is more
feasible than training on the entire data set
</p>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9332ee5" class="outline-4">
<h4 id="org9332ee5">Evaluating Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
feed_dict_test = {x: mnist.test.images,
                  y_true: mnist.test.labels,
                  y_true_cls: mnist.test.cls}

def print_accuracy():
    # Use TensorFlow to compute the accuracy.
    acc = session.run(accuracy, feed_dict=feed_dict_test)

    # Print the accuracy.
    print("Accuracy on test-set: {0:.1%}".format(acc))
</pre>

</div>

<p>
Approx 91% is very bad, 6 digit ZIP code would have an accuracy rate of 57% 
</p>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org8ea1dc7" class="outline-3">
<h3 id="org8ea1dc7">Convolutional Neural Network</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7119cb2" class="outline-4">
<h4 id="org7119cb2">Flowchart</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/cnn_network_flowchart.png" alt="cnn_network_flowchart.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org31ff89e" class="outline-4">
<h4 id="org31ff89e">Introduction</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolutional Networks work by moving smaller filter across the input image</li>
<li>Filters are re-used for recognizing patters throughout the entire input image</li>
<li>This makes Convolutional Networks much more powerful than Fully-Connected
networks with the same number of variables</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3f0b41c" class="outline-4">
<h4 id="org3f0b41c">Features</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features.png" alt="features.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdc71da2" class="outline-4">
<h4 id="orgdc71da2">Features (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features_2.png" alt="features_2.png" width="60%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3d565d8" class="outline-4">
<h4 id="org3d565d8">Convolution</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution.png" alt="convolution.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfaf04d4" class="outline-4">
<h4 id="orgfaf04d4">Convolution (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_2.png" alt="convolution_2.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge27974d" class="outline-4">
<h4 id="orge27974d">Convolution (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_3.png" alt="convolution_3.png" width="95%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org57e91b8" class="outline-4">
<h4 id="org57e91b8">Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling.png" alt="pooling.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd625a1f" class="outline-4">
<h4 id="orgd625a1f">Pooling (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling_2.png" alt="pooling_2.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdb10e5b" class="outline-4">
<h4 id="orgdb10e5b">Fully Connected Layers</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/layers.png" alt="layers.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6f85254" class="outline-4">
<h4 id="org6f85254">Hyper Parameters</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolution:
<ul>
<li>Number of features</li>
<li>Size of features</li>
</ul></li>
<li>Pooling
<ul>
<li>Window size</li>
<li>Window stride</li>
</ul></li>
<li>Fully Connected
<ul>
<li>number of neurons</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgf0ddf00" class="outline-4">
<h4 id="orgf0ddf00">Weight Initialization</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Helper functions to create ReLU neurons
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.05)
  return tf.Variable(initial)

def new_biases(length):
    return tf.Variable(tf.constant(0.05, shape=[length]))
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfd0fa57" class="outline-4">
<h4 id="orgfd0fa57">Creating a new Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Input is a 4-dim tensor:
</p>
<ol>
<li>image number</li>
<li>y-axis of each image</li>
<li>x-axis of each image</li>
<li>channels of each image</li>
</ol>

<p>
Output is another 4-dim tensor:
</p>
<ol>
<li>image number, same as input</li>
<li>y-axis of each image, might be smaller if pooling is used</li>
<li>x-axis of each image, might be smaller if pooling is used</li>
<li>channels produced by the convolutional filters</li>
</ol>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4d5476a" class="outline-4">
<h4 id="org4d5476a">Helper Function for Creating a New Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def new_conv_layer(input,              # The previous layer.
                   num_input_channels, # Num. channels in prev. layer.
                   filter_size,        # Width and height of each filter.
                   num_filters,        # Number of filters.
                   use_pooling=True):  # Use 2x2 max-pooling.
    # ...

    return layer, weights
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge146683" class="outline-4">
<h4 id="orge146683">Flattening a Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>convolutional layer produces an output tensor with 4 dimensions</li>
<li>fully connected layer will reduce 4-dim tensor to a 2-dim tensor that can be used as input to the fully connected layer</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def flatten_layer(layer):
    # ...

    # return both the flatten layer and number of features
    return layer_flat, num_features
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfcc263e" class="outline-4">
<h4 id="orgfcc263e">Creating a Fully-Connected Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Assumed that input is a 2-dim tensor of shape <code>[num_images, num_inputs]</code>, output is a 2-dim tensor of shape <code>[num_images, num_outputs]</code>
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def new_fc_layer(input,          # The previous layer.
                 num_inputs,     # Num. inputs from prev. layer.
                 num_outputs,    # Num. outputs.
                 use_relu=True): # Use Rectified Linear Unit (ReLU)?
    # create new weights and biases
    # calculate new layer
    # use ReLU?

    return layer
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb55980f" class="outline-4">
<h4 id="orgb55980f">Placeholder Variables</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>x</code> is the placeholder variable for input images
<ul>
<li>data-type is set to <code>float32</code></li>
<li>shape is set to <code>[None, img_size_flat]</code></li>
</ul></li>
<li>convolutional layers expect <code>x</code> to be encoded as a 4-dim tensor, so its shape
is <code>[num_images, img_height, img_width, num_channels]</code></li>
<li>also have placeholder for true labels</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')
x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])
y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')
y_true_cls = tf.argmax(y_true, axis=1)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4f8ae56" class="outline-4">
<h4 id="org4f8ae56">First Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>takes <code>x_image</code> as input and creates <code>num_filters1</code> different filters
<ul>
<li>each filter has width and height equal to filter<sub>size1</sub>=</li>
</ul></li>
<li>down sample the image so its half the size by using max-pooling</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
layer_conv1, weights_conv1 = \
    new_conv_layer(input=x_image,
                   num_input_channels=num_channels,
                   filter_size=filter_size1,
                   num_filters=num_filters1,
                   use_pooling=True)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org53bb08f" class="outline-4">
<h4 id="org53bb08f">Second Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>takes as input the output from the first convolutional layer</li>
<li>number of iunput channels = number of filters in the first convolutional layer</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
layer_conv2, weights_conv2 = \
    new_conv_layer(input=layer_conv1,
                   num_input_channels=num_filters1,
                   filter_size=filter_size2,
                   num_filters=num_filters2,
                   use_pooling=True)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc498f5d" class="outline-4">
<h4 id="orgc498f5d">Flatten Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>use output of convolutional layer as input to a fully-connected network, which
requires for the tensors to be reshaped to a 2-dim tensors</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
layer_flat, num_features = flatten_layer(layer_conv2)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org2abb0e9" class="outline-4">
<h4 id="org2abb0e9">Fully-Connected Layer 1</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
layer_fc1 = new_fc_layer(input=layer_flat,
                         num_inputs=num_features,
                         num_outputs=fc_size,
                         use_relu=True)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6dfc4fd" class="outline-4">
<h4 id="org6dfc4fd">Fully-Connected Layer 2</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
layer_fc2 = new_fc_layer(input=layer_fc1,
                         num_inputs=fc_size,
                         num_outputs=num_classes,
                         use_relu=False)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc2221c1" class="outline-4">
<h4 id="orgc2221c1">Cost Function and Optimization Method</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
y_pred = tf.nn.softmax(layer_fc2)
y_pred_cls = tf.argmax(y_pred, axis=1)
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,
                                                        labels=y_true)
cost = tf.reduce_mean(cross_entropy)
optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</pre>

</div>


</article>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org4393209" class="outline-3">
<h3 id="org4393209">Saving and Restoring your model</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc28168f" class="outline-4">
<h4 id="orgc28168f">Exporting the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>We can export the model for use in our own applications</li>
<li>use <code>tf.train.Saver</code> to save the graph and the trained weights</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
model_path = "./tmp/model.ckpt"
save_path = saver.save(sess, model_path) # saver is not declared???
print("Model saved in file: %s" % save_path)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4ab85f8" class="outline-4">
<h4 id="org4ab85f8">Restoring the Session</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
saver = tf.train.Saver()
model_path = "./tmp/model.ckpt"
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  saver.restore(sess, model_path)
  print("Accuracy:", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))
</pre>

</div>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge84d53c" class="outline-3">
<h3 id="orge84d53c">Toy Program</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/toy_program.png" alt="toy_program.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org267cf12" class="outline-2">
<h2 id="org267cf12">References</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><a href="https://github.com/PythonWorkshop/intro-to-tensorflow/blob/master/MathPrimer/Math%20primer%20for%20ML%20&amp;%20TensorFlow%20workshop.ipynb">Machine Learning Primer</a></li>
<li><a href="http://brohrer.github.io/how_convolutional_neural_networks_work.html">http://brohrer.github.io/how_convolutional_neural_networks_work.html</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/pros">https://www.tensorflow.org/get_started/mnist/pros</a></li>
<li><a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials">https://github.com/Hvass-Labs/TensorFlow-Tutorials</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-" class=" thank-you-slide segue nobackground" style="background-image: url(nil)">
<aside class="gdbar right"><img src="images/tensorflow.png"></aside><article class="flexbox vleft auto-fadein" id="text-">
<h2>
  <p>Thank You</p>
</h2>
<br>
<p class="auto-fadein" data-config-contact>
</p>
</article>

</slide>
<slide class="backdrop"></slide>
</slides> 
<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body> 

</html>
