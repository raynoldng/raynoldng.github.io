<!DOCTYPE html>
<html>
<head>
<title></title>
<!-- 2017-10-20 Fri 13:53 -->
<meta  charset="utf-8" />
<meta  htto-equiv="X-UA-Compatible" content="chrome=1" />
<meta  name="generator" content="Org-mode with org-ioslide" />
<meta  name="author" content="Raynold Ng" />


<!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--This one seems to work all the time, but really small on ipad-->
<!--<meta name="viewport" content="initial-scale=0.4">-->
<meta name="apple-mobile-web-app-capable" content="yes" />
<link rel="stylesheet" media="all" href="theme/css/default.css" />
<link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css" />
<link rel="stylesheet" media="all" href="theme/css/small-icon.css" />
<base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
<script data-main="js/slides" src="js/require-1.0.8.min.js"></script>

   <script src="js/jquery-1.7.1.min.js" type="text/javascript"></script>

<script src="js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML,local/local" type="text/javascript"></script>
</head>
<body style="opacity: 0">
<slides class="layout-widescreen">
<slide class="title-slide segue nobackground">
       <aside class="gdbar"><img src="images/tensorflow.png"></aside>
       <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
       <hgroup class="auto-fadein">
         <h1 data-config-title><!-- populated from slide_config.json --></h1>
         <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
         <p data-config-presenter><!-- populated from slide_config.json --></p>
       </hgroup>
    </slide>
  <p>
shackers
</p>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3284c23" class="outline-2">
<h2 id="org3284c23">Agenda</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Installation and Setup</li>
<li>What's TensorFlow?</li>
<li>Machine Learning Primer</li>
<li>Basic TensorFlow concepts</li>
<li>MNIST Example
<ul>
<li>Softmax</li>
<li>Convoluted Neural Networks</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org316eafa" class="outline-2">
<h2 id="org316eafa">Installation and Setup</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Ensure that you have the following installed:
</p>
<ol>
<li>TensorFlow: <a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a></li>
<li>Python 3: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
<li>Jupyter (recommended): <a href="http://jupyter.org/">http://jupyter.org/</a></li>
</ol>

<p>
Materials are available <a href="https://github.com/raynoldng/hackerschool-tensorflow">here</a>
</p>


</article>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org0a69a0b" class="outline-2">
<h2 id="org0a69a0b">Machine Learning Primer</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc7c0caf" class="outline-3">
<h3 id="orgc7c0caf">Structure in data</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>some interpretations to "structure in data"
<ul>
<li>given some data, one can predict other data points with some confidence</li>
<li>one can compress the data, i.e., store the same amount of information, with
less space</li>
</ul></li>
</ul>

\begin{align*}
A = \{1, 2, 6, 4, 7, 9, 0\} \\
B = \{1, 2, 1, 2, 1, 2, 1\}
\end{align*}

<ul>
<li>we might say that \(A\) has apparent structure while \(B\) does not</li>
</ul>


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org91f6572" class="outline-4">
<h4 id="org91f6572">Entropy</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>quantified as Entropy of Process</li>
</ul>
<p>
\[H(X) = -\sum_{i=1}^{N} p(x_i) \log p(x_i)\]
</p>
<ul>
<li>If entropy increases, uncertainty in prediction increases</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3122bdc" class="outline-4">
<h4 id="org3122bdc">Entropy (examples)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Example: fair dice</li>
</ul>
<p>
\[H(\text{fair dice roll}) = -\sum_{i=1}^6 \frac{1}{6} \log \frac{1}{6}=2.58\]
</p>
<ul>
<li>Example: biased 20:80 coin</li>
</ul>
<p>
\[H(20/80 \text{ coin toss}) = -\frac{1}{5}\log \frac{1}{5}-\frac{4}{5}\log \frac{4}{5} = 0.72\]
</p>
<ul>
<li>biased coin toss has lower entropy; predicting its outcome is easier than a fair dice</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgab63aba" class="outline-3">
<h3 id="orgab63aba">Basic Concepts for TensorFlow</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Recall from linear algebra that:
</p>
<ul>
<li>Scalar: an array in 0-D</li>
<li>Vector: an array in 1-D</li>
<li>Matrix: an array in 2-D</li>
</ul>

<p>
All are <b>tensors</b> of n-order. Similary, tensors can be transformed with
operations. Simple linear regression model:
</p>

<p>
\[w_o + w_1 x = \hat{y}\]
</p>

<p>
\(w_0\) and \(w_1\) are <b>weights</b>, that are determined during training. \(\hat{y}\) is
predicted outcome
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge3914a4" class="outline-3">
<h3 id="orge3914a4">Graph Representation of ML Models</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Can represent linear regression as a graph
</p>


<div class="figure">
<p><img src="images/linear_reg_graph.png" alt="linear_reg_graph.png" width="40%" />
</p>
</div>

<ul>
<li>operations are represented as nodes</li>
<li>graph shows how data is transformed by nodes and what is passed between them</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org15198d2" class="outline-3">
<h3 id="org15198d2">Graph Representation of ML Models (1)</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Consider a slightly larger neural net graph:
</p>

<div class="figure">
<p><img src="images/neural_net.png" alt="neural_net.png" width="50%" />
</p>
</div>

<p>
For more complex models, it could be helpful to visualize your graph.
<a href="https://www.tensorflow.org/versions/r0.7/how_tos/graph_viz/index.html">TensorBoard</a> provides this virtualization tool
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga55b6ea" class="outline-3">
<h3 id="orga55b6ea">Activation Functions</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>A popular function is the rectified linear unit (<b>ReLU</b>):</li>
</ul>
<p>
\[g(u) = max(0, u)\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/relu.png" alt="relu.png" width="70%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga4bd541" class="outline-3">
<h3 id="orga4bd541">Model Output</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>output depends on activation function used, but is generally any real number \([-\infty, \infty]\)</li>
<li>For binary classification, an additional sigmoid function can be applied to
bring the output to range of \([0,1]\)</li>
</ul>
<p>
\[S(x) = \frac{1}{1+e^{-x}}\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sigmoid.png" alt="sigmoid.png" width="90%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge37923d" class="outline-3">
<h3 id="orge37923d">Softmax Function</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>for multi-class prediction a softmax function is used:</li>
</ul>
<p>
\[S_j(\boldsymbol{z}) = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \text{ for }j=1,\dots,k\]
</p>
<ul>
<li>squash \(K\) dimensional vector <b>z</b> to a \(K\) dimensional vector that sum to 1</li>
</ul>
<p>
\[\sum_{j=1}^k S_j(\boldsymbol{z}) = 1\]
</p>
<ul>
<li>state usually represented with <b>one-hot encoding</b>, e.g for dice roll \((0,0,1,0,0,0)\)</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org73ec59c" class="outline-2">
<h2 id="org73ec59c">Basic TensorFlow Concepts</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org98b7bdb" class="outline-3">
<h3 id="org98b7bdb">What is TensorFlow?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>It is Google's AI Engine</li>
<li>"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms"</li>
<li>Originally developed Google Brain Team to conduct machine learning research and deep neural networks research</li>
<li>General enough to be applicable to a wide variety of other domains</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4455e2e" class="outline-3">
<h3 id="org4455e2e">Data Flow Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Tensorflow separates definition of computations from their execution
</p>

<p>
Phases:
</p>
<ol>
<li>assemble the graph</li>
<li>use a <code>session</code> to execute operations in the graph</li>
</ol>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
a = tf.add(3,5)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge033e0b" class="outline-3">
<h3 id="orge033e0b">Visualizing with TensorBoard</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.summary.FileWriter</code> serializes the graph into a format the TensorBoard can read</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
tf.summary.FileWriter("logs", tf.get_default_graph()).close()
</pre>

</div>

<ul>
<li>in the same directory, run:</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="sh">
tensorboard --logdir=logs
</pre>

</div>

<ul>
<li>This will launch an instance of TensorBoard that you can access at <a href="http://localhost:6006">http://localhost:6006</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd02c4cb" class="outline-3">
<h3 id="orgd02c4cb">How to get value of <code>a</code>?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
print(a)
</pre>

</div>

<p>
Create a <code>session</code>, and within it, evaluate the graph
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
print(sess.run(a))
sess.close()
</pre>

</div>

<p>
Alternatively:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
with tf.Session() as sess:
    print(sess.run(a))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org2938e42" class="outline-3">
<h3 id="org2938e42">Practice with More Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Try to generate the following graph: (insert equation)
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/graph2.png" alt="graph2.png" width="70%" />
</p>
</div>
</article>

<p>
Useful functions: <code>tf.add</code>, <code>tf.multiply</code>, <code>tf.pow</code>
</p>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdacb1ce" class="outline-3">
<h3 id="orgdacb1ce">Solution</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = 2
y = 3
op1 = tf.add(x, y)
op2 = tf.multiply(x, y)
op3 = tf.pow(op1, op2)
with tf.Session() as sess:
    op3 = sess.run(op3)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org214e51e" class="outline-3">
<h3 id="org214e51e">TensorFlow Variables</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>TensorFlow variables used to represent shared, persistant state manipulated by your program</li>
<li>variables hold and update parameters in your model during training</li>
<li>variables contain tensors</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W1 = tf.ones((2,2))
W2 = tf.Variable(tf.zeros((2,2)), name="weights")

with tf.Session() as sess:
    print(sess.run(W1))
    sess.run(tf.global_variables_initializer())
    print(sess.run(W2))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org12d13be" class="outline-3">
<h3 id="org12d13be">Updating Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <code>tf.assign</code> to assign a value to a variable
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
state = tf.Variable(0, name="counter")
new_value = tf.add(state, tf.constant(1))
update = tf.assign(state, new_value)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(state))
    for _ in range(3):
        sess.run(update)
        print(sess.run(state))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org624dfb0" class="outline-3">
<h3 id="org624dfb0">Fetching Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)
intermed = tf.add(input2, input3)
mul = tf.multiply(input1, intermed)

with tf.Session() as sess:
    result = sess.run([mul, intermed])
    print(result)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1f8d5f1" class="outline-3">
<h3 id="org1f8d5f1">TensorFlow Placeholders</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.placeholder</code> variables represent our input data</li>
<li><code>feed_dict</code> is a python dictionary that maps <code>tf.placeholder</code> variables to data</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)

output = tf.multiply(input1, input2)

with tf.Session() as sess:
    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org0f59448" class="outline-3">
<h3 id="org0f59448">Example: Linear Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge1d4930" class="outline-4">
<h4 id="orge1d4930">Recap</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>we have two weights \(w_0\) and \(w_1\), we want the model to figure out good weights by minimizing prediction error</li>
<li>define the following <b>loss function</b></li>
</ul>

<p>
\[L = \sum (y - \hat{y})^2\]
</p>

<p>
Supose we want to model the following "unknown" function:
</p>

<p>
\[y = x + 20 \sin(x/10)\]
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9fc46e4" class="outline-4">
<h4 id="org9fc46e4">Scatter Plot</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sample_data.png" alt="sample_data.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org27e521a" class="outline-4">
<h4 id="org27e521a">Define Variables and Placeholders</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define data size and batch size
n_samples = 1000
batch_size = 100

# TensorFlow is particular about shapes, so resize
X_data = np.reshape(X_data, (n_samples, 1))
y_data = np.reshape(y_data, (n_samples, 1))

# Define placeholders for input
X = tf.placeholder(tf.float32, shape=(batch_size, 1))
y = tf.placeholder(tf.float32, shape=(batch_size, 1))
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org86cff15" class="outline-4">
<h4 id="org86cff15">Loss Function</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Loss function is defined as:
\[J(W,b) = \frac{1}{N}\sum_{i=1}^{N}(y_i-(W_{x_i}+b))^2\]
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define variables to be learned
with tf.variable_scope("linear-regression"):
    W = tf.get_variable("weights", (1,1),
                        initializer = tf.random_normal_initializer())
    b = tf.get_variable("bias", (1,),
                        initializer = tf.constant_initializer(0.0))
    y_pred = tf.matmul(X, W) + b
    loss = tf.reduce_sum((y - y_pred)**2/n_samples)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge7b8c99" class="outline-4">
<h4 id="orge7b8c99">Define Optimizer and Train Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="smaller" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define optimizer operation
opt_operation = tf.train.AdamOptimizer().minimize(loss)
with tf.Session() as sess:
    # Initialize all variables in graph
    sess.run(tf.global_variables_initializer())
    # Gradient descent for 500 steps:
    for _ in range(500):
        # Select from random mini batch
        indices = np.random.choice(n_samples, batch_size)
        X_batch, y_batch = X_data[indices], y_data[indices]
        # Do gradient descent step
        _, loss_val = sess.run([opt_operation, loss], feed_dict={X: X_batch, y: y_batch})
    print(sess.run([W, b]))
    # Display results
    plt.scatter(X_data, y_data)
    plt.scatter(X_data, sess.run(W) * X_data + sess.run(b), c='g')
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgbce1b9b" class="outline-4">
<h4 id="orgbce1b9b">Results</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/trained_model.png" alt="trained_model.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgaa2b598" class="outline-2">
<h2 id="orgaa2b598">MNIST and TensorFlow</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org21a364c" class="outline-3">
<h3 id="org21a364c">Introduction</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>MNIST is the hello world of machine learning</li>
<li>Simple computer vision dataset, consists of images of handwritten digits</li>
<li>We are going to train a model to predict what the digits are</li>
</ul>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/MNIST.png" alt="MNIST.png" width="80%" />
</p>
</div>
</article>


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org18fea2c" class="outline-4">
<h4 id="org18fea2c">Importing MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
To download and read in the data automatically:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
</pre>

</div>

<p>
One hot encoding
</p>
<ul>
<li>labels have been converted to a vector of length equal to number of classes.</li>
<li>the ith element is 1, rest are 0. E.g. Digit 1: \([0,1,\dots]\)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7845c1a" class="outline-4">
<h4 id="org7845c1a">MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
The MNIST data is split into three parts:
</p>
<ol>
<li>55,000 data points of training data (<code>mnist.train</code>)</li>
<li>10,000 data points of test data (<code>mnist.test</code>)</li>
<li>5,000 data points of validation data (<code>mnist.validation</code>)</li>
</ol>

<p>
Every MNIST data has 2 parts:
</p>
<ol>
<li>an image of a handwritten digit (call it "x")</li>
<li>corresponding label (call it "y")</li>
</ol>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgfc6e785" class="outline-3">
<h3 id="orgfc6e785">Softmax Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org768939a" class="outline-4">
<h4 id="org768939a">Overview</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">

<div class="figure">
<p><img src="images/softmax_1.png" alt="softmax_1.png" width="80%" />
</p>
</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd8703e1" class="outline-4">
<h4 id="orgd8703e1">Overview (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_2.png" alt="softmax_2.png" width="120%" />
</p>
</div>
</article>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_3.png" alt="softmax_3.png" width="120%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdd12a19" class="outline-4">
<h4 id="orgdd12a19">Defining Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>multiply 784-dimensional vectors by \(W\) to produce 10-dimensional vectors of evidence</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

y = tf.nn.softmax(tf.matmul(x, W) + b)
</pre>

</div>
<ul>
<li>multiply <code>x</code> with <code>W</code> in that order as <code>x</code> has shape <code>[None, 784]</code> and <code>W</code> has shape <code>[784, 10]</code></li>
<li>Small trick to deal with <code>x</code> being a 2D tensor with multiple inputs.</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5e4155f" class="outline-4">
<h4 id="org5e4155f">Training</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <b>cross-entropy</b> to determine loss of model:
\[H_{y'}=-\sum_{i} y_i' \log(y_i)\]
</p>

<p>
Where:
</p>
<ul>
<li>\(y\) is our predicted probability distribution</li>
<li>\(y'\) is the true distribution (one-hot vector with digit labels)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1a6723e" class="outline-4">
<h4 id="org1a6723e">Training (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Need a placeholder to implement cross entropy:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), 
                                              reduction_indices = [1]))
</pre>

</div>

<p>
<code>tf.reduce_sum</code> computes the sum of elements across dimensions of a tensor
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# 'x' is [[1, 1, 1]
#         [1, 1, 1]]
tf.reduce_sum(x) ==&gt; 6
tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]
tf.reduce_sum(x, 1) ==&gt; [3, 3]
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7cdd48f" class="outline-4">
<h4 id="org7cdd48f">Training (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
for _ in range(400):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
</pre>

</div>

<p>
Using small batches of random data is called <b>stochastic training</b>, it is more
feasible than training on the entire data set
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge5d3cd1" class="outline-4">
<h4 id="orge5d3cd1">Evaluating Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.argmax</code> is an extrememly helpful function that returns the index of the highest entry in a tensor along some axis.</li>
<li><code>tf.argmax(y,1)</code> is predicted label while <code>tf.argmax(y_, 1)</code> is the actual label</li>
<li><code>tf.equal</code> to check if prediction matches the true</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
</pre>

</div>

<p>
Approx 91% is very bad, 6 digit ZIP code would have an accuracy rate of 57% 
</p>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgf6c0d07" class="outline-3">
<h3 id="orgf6c0d07">Convolutional Neural Network</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgcb0c470" class="outline-4">
<h4 id="orgcb0c470">Flowchart</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/cnn_network_flowchart.png" alt="cnn_network_flowchart.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org977cc24" class="outline-4">
<h4 id="org977cc24">Introduction</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolutional Networks work by moving smaller filter across the input image</li>
<li>Filters are re-used for recognizing patters throughout the entire input image</li>
<li>This makes Convolutional Networks much more powerfule than Fully-Connected
networks with the same number of variables</li>
<li>Convolutional Networks are also faster to train</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1f566c9" class="outline-4">
<h4 id="org1f566c9">Features</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features.png" alt="features.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1d563ea" class="outline-4">
<h4 id="org1d563ea">Features (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features_2.png" alt="features_2.png" width="60%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3c93d4e" class="outline-4">
<h4 id="org3c93d4e">Convolution</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution.png" alt="convolution.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5fd5410" class="outline-4">
<h4 id="org5fd5410">Convolution (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_2.png" alt="convolution_2.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4534103" class="outline-4">
<h4 id="org4534103">Convolution (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_3.png" alt="convolution_3.png" width="95%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org795d251" class="outline-4">
<h4 id="org795d251">Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling.png" alt="pooling.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc17f7bd" class="outline-4">
<h4 id="orgc17f7bd">Pooling (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling_2.png" alt="pooling_2.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org51eb7c7" class="outline-4">
<h4 id="org51eb7c7">Fully Connected Layers</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/layers.png" alt="layers.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org2d308f3" class="outline-4">
<h4 id="org2d308f3">Hyper Parameters</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolution:
<ul>
<li>Number of features</li>
<li>Size of features</li>
</ul></li>
<li>Pooling
<ul>
<li>Window size</li>
<li>Window stride</li>
</ul></li>
<li>Fully Connected
<ul>
<li>number of neurons</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org79d0ea3" class="outline-4">
<h4 id="org79d0ea3">Weight Initialization</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Helper functions to create ReLU neurons
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1196d7b" class="outline-4">
<h4 id="org1196d7b">Convolution and Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgafd6998" class="outline-4">
<h4 id="orgafd6998">First Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>first layer consists of convolution and then max pooling</li>
<li>compute 32 fearures for each 5x5 patch</li>
<li>also define our bias</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
x_image = tf.reshape(x, [-1, 28, 28, 1]) # ?, width, height, number of color channels
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1) # reduce image to 14x14
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4cf0594" class="outline-4">
<h4 id="org4cf0594">Second Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>64 features for each 5x5 patch</li>
<li>image is now 7x7</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3994ba1" class="outline-4">
<h4 id="org3994ba1">Densely Connected Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>add a fully connected layer with 1024 neurons to allow processing of the entire image</li>
<li>reshape tensor from pooling layer into batch of vectors, muplity by a weight matrix, add a bias and then apply ReLU</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org8e4bcea" class="outline-4">
<h4 id="org8e4bcea">Read Out Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Add one last layer, similar to softmax regression
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6a28e86" class="outline-4">
<h4 id="org6a28e86">Train and Evaluate the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc23c932" class="outline-4">
<h4 id="orgc23c932">Train and Evaluate the Model (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
sess.run(tf.global_variables_initializer())
with sess.as_default():
    for i in range(500):
        batch = mnist.train.next_batch(50)
    if i % 100 == 0:
        train_accuracy = accuracy.eval(feed_dict={
          x: batch[0], y_: batch[1]})
        print('step %d, training accuracy %g' % (i, train_accuracy))
        train_step.run(feed_dict={x: batch[0], y_: batch[1]})

    print('test accuracy %g' % accuracy.eval(feed_dict={
      x: mnist.test.images, y_: mnist.test.labels}))
</pre>

</div>


</article>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org5546345" class="outline-3">
<h3 id="org5546345">Saving and Restoring your model</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd9f658d" class="outline-4">
<h4 id="orgd9f658d">Exporting the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>We can export the model for use in our own applications</li>
<li>use <code>tf.train.Saver</code> to save the graph and the trained weights</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
model_path = "./tmp/model.ckpt"
save_path = saver.save(sess, model_path) # saver is not declared???
print("Model saved in file: %s" % save_path)
</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1981df7" class="outline-4">
<h4 id="org1981df7">Restoring the Session</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
saver = tf.train.Saver()
model_path = "./tmp/model.ckpt"
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  saver.restore(sess, model_path)
  print("Accuracy:", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))
</pre>

</div>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgf1ce056" class="outline-3">
<h3 id="orgf1ce056">Toy Program</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/toy_program.png" alt="toy_program.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgab4498d" class="outline-2">
<h2 id="orgab4498d">References</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><a href="https://github.com/PythonWorkshop/intro-to-tensorflow/blob/master/MathPrimer/Math%20primer%20for%20ML%20&amp;%20TensorFlow%20workshop.ipynb">Machine Learning Primer</a></li>
<li><a href="http://brohrer.github.io/how_convolutional_neural_networks_work.html">http://brohrer.github.io/how_convolutional_neural_networks_work.html</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/pros">https://www.tensorflow.org/get_started/mnist/pros</a></li>
<li><a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials">https://github.com/Hvass-Labs/TensorFlow-Tutorials</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-" class=" thank-you-slide segue nobackground" style="background-image: url(nil)">
<aside class="gdbar right"><img src="images/tensorflow.png"></aside><article class="flexbox vleft auto-fadein" id="text-">
<h2>
  <p>Thank You</p>
</h2>
<br>
<p class="auto-fadein" data-config-contact>
</p>
</article>

</slide>
<slide class="backdrop"></slide>
</slides> 
<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body> 

</html>
