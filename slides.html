<!DOCTYPE html>
<html>
<head>
<title></title>
<!-- 2017-10-20 Fri 00:15 -->
<meta  charset="utf-8" />
<meta  htto-equiv="X-UA-Compatible" content="chrome=1" />
<meta  name="generator" content="Org-mode with org-ioslide" />
<meta  name="author" content="Raynold Ng" />


<!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
<!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--This one seems to work all the time, but really small on ipad-->
<!--<meta name="viewport" content="initial-scale=0.4">-->
<meta name="apple-mobile-web-app-capable" content="yes" />
<link rel="stylesheet" media="all" href="theme/css/default.css" />
<link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css" />
<link rel="stylesheet" media="all" href="theme/css/small-icon.css" />
<base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
<script data-main="js/slides" src="js/require-1.0.8.min.js"></script>

   <script src="js/jquery-1.7.1.min.js" type="text/javascript"></script>

<script src="js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML,local/local" type="text/javascript"></script>
</head>
<body style="opacity: 0">
<slides class="layout-widescreen">
<slide class="title-slide segue nobackground">
       <aside class="gdbar"><img src="images/tensorflow.png"></aside>
       <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
       <hgroup class="auto-fadein">
         <h1 data-config-title><!-- populated from slide_config.json --></h1>
         <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
         <p data-config-presenter><!-- populated from slide_config.json --></p>
       </hgroup>
    </slide>
  <slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb59d4ea" class="outline-2">
<h2 id="orgb59d4ea">Agenda</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Installation and Setup</li>
<li>What's TensorFlow?</li>
<li>Machine Learning Primer</li>
<li>Basic TensorFlow concepts</li>
<li>MNIST Example
<ul>
<li>Softmax</li>
<li>Convoluted Neural Networks</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org75e363e" class="outline-2">
<h2 id="org75e363e">Installation and Setup</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Ensure that you have the following installed:
</p>
<ol>
<li>TensorFlow: <a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a></li>
<li>Python 3: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
<li>Jupyter (recommended): <a href="http://jupyter.org/">http://jupyter.org/</a></li>
</ol>

<p>
Materials are available <a href="https://github.com/raynoldng/hackerschool-tensorflow">here</a>
</p>


</article>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org4b0f017" class="outline-2">
<h2 id="org4b0f017">Machine Learning Primer</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd216ca0" class="outline-3">
<h3 id="orgd216ca0">Structure in data</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>some interpretations to "structure in data"
<ul>
<li>given some data, one can predict other data points with some confidence</li>
<li>one can compress the data, i.e., store the same amount of information, with
less space</li>
</ul></li>
</ul>

\begin{align*}
A = \{1, 2, 6, 4, 7, 9, 0\} \\
B = \{1, 2, 1, 2, 1, 2, 1\}
\end{align*}

<ul>
<li>we might say that \(A\) has apparent structure while \(B\) does not</li>
</ul>


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org02542b6" class="outline-4">
<h4 id="org02542b6">Entropy</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>quantified as Entropy of Process</li>
</ul>
<p>
\[H(X) = -\sum_{i=1}^{N} p(x_i) \log p(x_i)\]
</p>
<ul>
<li>If entropy increases, uncertainty in prediction increases</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org9b6a36c" class="outline-4">
<h4 id="org9b6a36c">Entropy (examples)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Example: fair dice</li>
</ul>
<p>
\[H(\text{fair dice roll}) = -\sum_{i=1}^6 \frac{1}{6} \log \frac{1}{6}=2.58\]
</p>
<ul>
<li>Example: biased 20:80 coin</li>
</ul>
<p>
\[H(20/80 \text{ coin toss}) = -\frac{1}{5}\log \frac{1}{5}-\frac{4}{5}\log \frac{4}{5} = 0.72\]
</p>
<ul>
<li>biased coin toss has lower entropy; predicting its outcome is easier than a fair dice</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org551d225" class="outline-3">
<h3 id="org551d225">Basic Concepts for TensorFlow</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Recall from linear algebra that:
</p>
<ul>
<li>Scalar: an array in 0-D</li>
<li>Vector: an array in 1-D</li>
<li>Matrix: an array in 2-D</li>
</ul>

<p>
All are <b>tensors</b> of n-order. Similary, tensors can be transformed with
operations. Simple linear regression model:
</p>

<p>
\[w_o + w_1 x = \hat{y}\]
</p>

<p>
\(w_0\) and \(w_1\) are <b>weights</b>, that are determined during training. \(\hat{y}\) is
predicted outcome
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc7b640a" class="outline-3">
<h3 id="orgc7b640a">Graph Representation of ML Models</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Can represent linear regression as a graph
</p>


<div class="figure">
<p><img src="images/linear_reg_graph.png" alt="linear_reg_graph.png" width="40%" />
</p>
</div>

<ul>
<li>operations are represented as nodes</li>
<li>graph shows how data is transformed by nodes and what is passed between them</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org03c1d8a" class="outline-3">
<h3 id="org03c1d8a">Graph Representation of ML Models (1)</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Consider a slightly larger neural net graph:
</p>

<div class="figure">
<p><img src="images/neural_net.png" alt="neural_net.png" width="50%" />
</p>
</div>

<p>
For more complex models, it could be helpful to visualize your graph.
<a href="https://www.tensorflow.org/versions/r0.7/how_tos/graph_viz/index.html">TensorBoard</a> provides this virtualization tool
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgbbb468b" class="outline-3">
<h3 id="orgbbb468b">Activation Functions</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>If \(g(u)\) is linear, then we return to linear regression</li>
<li>In practice, \(g(\dots)\) is non-linear, and a popular function is the rectified linear unit (<b>ReLU</b>):</li>
</ul>
<p>
\[g(u) = max(0, u)\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/relu.png" alt="relu.png" width="70%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc48987d" class="outline-3">
<h3 id="orgc48987d">Model Output</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>output depends on activation function used, but is generally any real number \([-\infty, \infty]\)</li>
<li>For binary classification, an additional sigmoid function can be applied to
bring the output to range of \([0,1]\)</li>
</ul>
<p>
\[S(x) = \frac{1}{1+e^{-x}}\]
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sigmoid.png" alt="sigmoid.png" width="90%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3d3d6fb" class="outline-3">
<h3 id="org3d3d6fb">Softmax Function</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>for multi-class prediction a softmax function is used:</li>
</ul>
<p>
\[S_j(\boldsymbol{z}) = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \text{ for }j=1,\dots,k\]
</p>
<ul>
<li>squash \(K\) dimensional vector <b>z</b> to a \(K\) dimensional vector that sum to 1</li>
</ul>
<p>
\[\sum_{j=1}^k S_j(\boldsymbol{z}) = 1\]
</p>
<ul>
<li>state usually represented with <b>one-hot encoding</b>, e.g for dice roll \((0,0,1,0,0,0)\)</li>
</ul>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-orgc0ed59a" class="outline-2">
<h2 id="orgc0ed59a">Basic TensorFlow Concepts</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga20573c" class="outline-3">
<h3 id="orga20573c">What is TensorFlow?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>It is Google's AI Engine</li>
<li>"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms"</li>
<li>Originally developed Google Brain Team to conduct machine learning research and deep neural networks research</li>
<li>General enough to be applicable to a wide variety of other domains</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1a467f3" class="outline-3">
<h3 id="org1a467f3">Data Flow Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Tensorflow separates definition of computations from their execution
</p>

<p>
Phases:
</p>
<ol>
<li>assemble the graph</li>
<li>use a <code>session</code> to execute operations in the graph</li>
</ol>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
a = tf.add(3,5)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb280e0f" class="outline-3">
<h3 id="orgb280e0f">Visualizing with TensorBoard</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.summary.FileWriter</code> serializes the graph into a format the TensorBoard can read</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
tf.summary.FileWriter("logs", tf.get_default_graph()).close()</pre>

</div>

<ul>
<li>in the same directory, run:</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="sh">
tensorboard --logdir=logs</pre>

</div>

<ul>
<li>This will launch an instance of TensorBoard that you can access at <a href="http://localhost:6006">http://localhost:6006</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd9e6828" class="outline-3">
<h3 id="orgd9e6828">How to get value of <code>a</code>?</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
print(a)</pre>

</div>

<p>
Create a <code>session</code>, and within it, evaluate the graph
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
print(sess.run(a))
sess.close()</pre>

</div>

<p>
Alternatively:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
with tf.Session() as sess:
    print(sess.run(a))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1a127a4" class="outline-3">
<h3 id="org1a127a4">Practice with More Graphs</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Try to generate the following graph:
</p>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/graph2.png" alt="graph2.png" width="70%" />
</p>
</div>
</article>

<p>
Useful functions: <code>tf.add</code>, <code>tf.multiply</code>, <code>tf.pow</code>
</p>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc2aaaff" class="outline-3">
<h3 id="orgc2aaaff">Solution</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = 2
y = 3
op1 = tf.add(x, y)
op2 = tf.multiply(x, y)
op3 = tf.pow(op1, op2)
with tf.Session() as sess:
    op3 = sess.run(op3)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge3d1f05" class="outline-3">
<h3 id="orge3d1f05">TensorFlow Variables</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>TensorFlow variables used to represent shared, persistant state manipulated by your program</li>
<li>variables hold and update parameters in your model during training</li>
<li>variables contain tensors</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W1 = tf.ones((2,2))
W2 = tf.Variable(tf.zeros((2,2)), name="weights")

with tf.Session() as sess:
    print(sess.run(W1))
    sess.run(tf.global_variables_initializer())
    print(sess.run(W2))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orged50343" class="outline-3">
<h3 id="orged50343">Updating Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <code>tf.assign</code> to assign a value to a variable
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
state = tf.Variable(0, name="counter")
new_value = tf.add(state, tf.constant(1))
update = tf.assign(state, new_value)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(state))
    for _ in range(3):
        sess.run(update)
        print(sess.run(state))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org8f36c0e" class="outline-3">
<h3 id="org8f36c0e">Fetching Variable State</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)
intermed = tf.add(input2, input3)
mul = tf.multiply(input1, intermed)

with tf.Session() as sess:
    result = sess.run([mul, intermed])
    print(result)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgce0b4c6" class="outline-3">
<h3 id="orgce0b4c6">TensorFlow Placeholders</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.placeholder</code> variables represent our input data</li>
<li><code>feed_dict</code> is a python dictionary that maps <code>tf.placeholder</code> variables to data</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)

output = tf.multiply(input1, input2)

with tf.Session() as sess:
    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org7de40bf" class="outline-3">
<h3 id="org7de40bf">Example: Linear Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6ea7b1f" class="outline-4">
<h4 id="org6ea7b1f">Recap</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>we have two weights \(w_0\) and \(w_1\), we want the model to figure out good weights by minimizing prediction error</li>
<li>define the following <b>loss function</b></li>
</ul>

<p>
\[L = \sum (y - \hat{y})^2\]
</p>

<p>
Supose we want to model the following "unknown" function:
</p>

<p>
\[y = x + 20 \sin(x/10)\]
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6f5e442" class="outline-4">
<h4 id="org6f5e442">Plot Input Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Make sure that <code>seaborn</code> and <code>matplotlib</code> are installed. If you are using Jupyter, add <code>%matplotlib inline</code> in the code cell.
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
import tensorflow as tf
import numpy as np
import seaborn
import matplotlib.pyplot as plt
%matplotlib inline
# Define input data
X_data = np.arange(100, step=.1)
y_data = X_data + 20 * np.sin(X_data/10)
# Plot input data
plt.scatter(X_data, y_data)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdee9295" class="outline-4">
<h4 id="orgdee9295">Scatter Plot</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/sample_data.png" alt="sample_data.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org94572d0" class="outline-4">
<h4 id="org94572d0">Define Variables and Placeholders</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define data size and batch size
n_samples = 1000
batch_size = 100

# TensorFlow is particular about shapes, so resize
X_data = np.reshape(X_data, (n_samples, 1))
y_data = np.reshape(y_data, (n_samples, 1))

# Define placeholders for input
X = tf.placeholder(tf.float32, shape=(batch_size, 1))
y = tf.placeholder(tf.float32, shape=(batch_size, 1))</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org515dbbf" class="outline-4">
<h4 id="org515dbbf">Loss Function</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Loss function is defined as:
\[J(W,b) = \frac{1}{N}\sum_{i=1}^{N}(y_i-(W_{x_i}+b))^2\]
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define variables to be learned
with tf.variable_scope("linear-regression"):
    W = tf.get_variable("weights", (1,1),
                        initializer = tf.random_normal_initializer())
    b = tf.get_variable("bias", (1,),
                        initializer = tf.constant_initializer(0.0))
    y_pred = tf.matmul(X, W) + b
    loss = tf.reduce_sum((y - y_pred)**2/n_samples)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org1d9c553" class="outline-4">
<h4 id="org1d9c553">Define Optimizer and Train Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="smaller" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# Define optimizer operation
opt_operation = tf.train.AdamOptimizer().minimize(loss)
with tf.Session() as sess:
    # Initialize all variables in graph
    sess.run(tf.global_variables_initializer())
    # Gradient descent for 500 steps:
    for _ in range(500):
        # Select from random mini batch
        indices = np.random.choice(n_samples, batch_size)
        X_batch, y_batch = X_data[indices], y_data[indices]
        # Do gradient descent step
        _, loss_val = sess.run([opt_operation, loss], feed_dict={X: X_batch, y: y_batch})
    print(sess.run([W, b]))
    # Display results
    plt.scatter(X_data, y_data)
    plt.scatter(X_data, sess.run(W) * X_data + sess.run(b), c='g')
</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7ea38b3" class="outline-4">
<h4 id="org7ea38b3">Results</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/trained_model.png" alt="trained_model.png" width="130%" />
</p>
</div>
</article>


</article>

</slide>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org73258e7" class="outline-2">
<h2 id="org73258e7">MNIST and TensorFlow</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org2e6db38" class="outline-3">
<h3 id="org2e6db38">Introduction</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>MNIST is the hello world of machine learning</li>
<li>Simple computer vision dataset, consists of images of handwritten digits</li>
<li>We are going to train a model to predict what the digits are</li>
</ul>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/MNIST.png" alt="MNIST.png" width="80%" />
</p>
</div>
</article>


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4e17049" class="outline-4">
<h4 id="org4e17049">Importing MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
To download and read in the data automatically:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)</pre>

</div>

<p>
One hot encoding
</p>
<ul>
<li>labels have been converted to a vector of length equal to number of classes.</li>
<li>the ith element is 1, rest are 0. E.g. Digit 1: \([0,1,\dots]\)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4004bd7" class="outline-4">
<h4 id="org4004bd7">MNIST Data</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
The MNIST data is split into three parts:
</p>
<ol>
<li>55,000 data points of training data (<code>mnist.train</code>)</li>
<li>10,000 data points of test data (<code>mnist.test</code>)</li>
<li>5,000 data points of validation data (<code>mnist.validation</code>)</li>
</ol>

<p>
Every MNIST data has 2 parts:
</p>
<ol>
<li>an image of a handwritten digit (call it "x")</li>
<li>corresponding label (call it "y")</li>
</ol>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org540e775" class="outline-3">
<h3 id="org540e775">Softmax Regression</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd19801a" class="outline-4">
<h4 id="orgd19801a">Overview</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">

<div class="figure">
<p><img src="images/softmax_1.png" alt="softmax_1.png" width="80%" />
</p>
</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgdad256b" class="outline-4">
<h4 id="orgdad256b">Overview (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_2.png" alt="softmax_2.png" width="120%" />
</p>
</div>
</article>

<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/softmax_3.png" alt="softmax_3.png" width="120%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgaa90068" class="outline-4">
<h4 id="orgaa90068">Defining Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>multiply 784-dimensional vectors by \(W\) to produce 10-dimensional vectors of evidence</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

y = tf.nn.softmax(tf.matmul(x, W) + b)</pre>

</div>
<ul>
<li>multiply <code>x</code> with <code>W</code> in that order as <code>x</code> has shape <code>[None, 784]</code> and <code>W</code> has shape <code>[784, 10]</code></li>
<li>Small trick to deal with <code>x</code> being a 2D tensor with multiple inputs.</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org63edc50" class="outline-4">
<h4 id="org63edc50">Training</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Use <b>cross-entropy</b> to determine loss of model:
\[H_{y'}=-\sum_{i} y_i' \log(y_i)\]
</p>

<p>
Where:
</p>
<ul>
<li>\(y\) is our predicted probability distribution</li>
<li>\(y'\) is the true distribution (one-hot vector with digit labels)</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5221163" class="outline-4">
<h4 id="org5221163">Training (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Need a placeholder to implement cross entropy:
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), 
                                              reduction_indices = [1]))</pre>

</div>

<p>
<code>tf.reduce_sum</code> computes the sum of elements across dimensions of a tensor
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
# 'x' is [[1, 1, 1]
#         [1, 1, 1]]
tf.reduce_sum(x) ==&gt; 6
tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]
tf.reduce_sum(x, 1) ==&gt; [3, 3]</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0375f38" class="outline-4">
<h4 id="org0375f38">Training (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
for _ in range(400):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})</pre>

</div>

<p>
Using small batches of random data is called <b>stochastic training</b>, it is more
feasible than training on the entire data set
</p>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge3534a8" class="outline-4">
<h4 id="orge3534a8">Evaluating Our Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><code>tf.argmax</code> is an extrememly helpful function that returns the index of the highest entry in a tensor along some axis.</li>
<li><code>tf.argmax(y,1)</code> is predicted label while <code>tf.argmax(y_, 1)</code> is the actual label</li>
<li><code>tf.equal</code> to check if prediction matches the true</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>

<p>
Approx 91% is very bad, 6 digit ZIP code would have an accuracy rate of 57% 
</p>


</article>

</slide>

</slide>
</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org86d0a2f" class="outline-3">
<h3 id="org86d0a2f">Convolutional Neural Network</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org67466a7" class="outline-4">
<h4 id="org67466a7">Introduction</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolutional Networks work by moving smaller filter across the input image</li>
<li>Filters are re-used for recognizing patters throughout the entire input image</li>
<li>This makes Convolutional Networks much more powerfule than Fully-Connected
networks with the same number of variables</li>
<li>Convolutional Networks are also faster to train</li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org6e6ba8e" class="outline-4">
<h4 id="org6e6ba8e">Flowchart</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/cnn_network_flowchart.png" alt="cnn_network_flowchart.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgc9b09a3" class="outline-4">
<h4 id="orgc9b09a3">Features</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features.png" alt="features.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org22099cf" class="outline-4">
<h4 id="org22099cf">Features (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/features_2.png" alt="features_2.png" width="60%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4f87e24" class="outline-4">
<h4 id="org4f87e24">Convolution</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution.png" alt="convolution.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgd3cbf50" class="outline-4">
<h4 id="orgd3cbf50">Convolution (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_2.png" alt="convolution_2.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org106904b" class="outline-4">
<h4 id="org106904b">Convolution (2)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/convolution_3.png" alt="convolution_3.png" width="95%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orge36f6c4" class="outline-4">
<h4 id="orge36f6c4">Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling.png" alt="pooling.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5e40b83" class="outline-4">
<h4 id="org5e40b83">Pooling (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/pooling_2.png" alt="pooling_2.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org5a05c8b" class="outline-4">
<h4 id="org5a05c8b">Fully Connected Layers</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/layers.png" alt="layers.png" width="100%" />
</p>
</div>
</article>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org3a55ccb" class="outline-4">
<h4 id="org3a55ccb">Hyper Parameters</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>Convolution:
<ul>
<li>Number of features</li>
<li>Size of features</li>
</ul></li>
<li>Pooling
<ul>
<li>Window size</li>
<li>Window stride</li>
</ul></li>
<li>Fully Connected
<ul>
<li>number of neurons</li>
</ul></li>
</ul>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org7a44ec1" class="outline-4">
<h4 id="org7a44ec1">Weight Initialization</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Helper functions to create ReLU neurons
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org687b3ac" class="outline-4">
<h4 id="org687b3ac">Convolution and Pooling</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org40fca8f" class="outline-4">
<h4 id="org40fca8f">First Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>first layer consists of convolution and then max pooling</li>
<li>compute 32 fearures for each 5x5 patch</li>
<li>also define our bias</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
x_image = tf.reshape(x, [-1, 28, 28, 1]) # ?, width, height, number of color channels
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1) # reduce image to 14x14</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgf71aa63" class="outline-4">
<h4 id="orgf71aa63">Second Convolutional Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>64 features for each 5x5 patch</li>
<li>image is now 7x7</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgfa835c3" class="outline-4">
<h4 id="orgfa835c3">Densely Connected Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>add a fully connected layer with 1024 neurons to allow processing of the entire image</li>
<li>reshape tensor from pooling layer into batch of vectors, muplity by a weight matrix, add a bias and then apply ReLU</li>
</ul>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org74c5e3e" class="outline-4">
<h4 id="org74c5e3e">Read Out Layer</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<p>
Add one last layer, similar to softmax regression
</p>

<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2</pre>

</div>


</article>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orga702579" class="outline-4">
<h4 id="orga702579">Train and Evaluate the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org41dc16c" class="outline-4">
<h4 id="org41dc16c">Train and Evaluate the Model (1)</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
sess = tf.Session()
sess.run(tf.global_variables_initializer())
with sess.as_default():
    for i in range(500):
        batch = mnist.train.next_batch(50)
    if i % 100 == 0:
        train_accuracy = accuracy.eval(feed_dict={
          x: batch[0], y_: batch[1]})
        print('step %d, training accuracy %g' % (i, train_accuracy))
        train_step.run(feed_dict={x: batch[0], y_: batch[1]})

    print('test accuracy %g' % accuracy.eval(feed_dict={
      x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>


</article>

</slide>

</slide>

</slide>
<slide id="sec-" class=" segue dark quote nobackground" style="background-image: url(nil)">
<aside class="gdbar right bottom"><img src="images/tensorflow.png"></aside><hgroup class="">
       <h2 class=" "><div id="outline-container-org19e4ccc" class="outline-3">
<h3 id="org19e4ccc">Saving and Restoring your model</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="flexbox vleft auto-fadein" id="text-">


</article>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-orgb904a4e" class="outline-4">
<h4 id="orgb904a4e">Exporting the Model</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li>We can export the model for use in our own applications</li>
<li>use <code>tf.train.Saver</code> to save the graph and the trained weights</li>
</ul>
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
model_path = "./tmp/model.ckpt"
save_path = saver.save(sess, model_path) # saver is not declared???
print("Model saved in file: %s" % save_path)</pre>

</div>


</article>

</slide>

</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org88c60c1" class="outline-4">
<h4 id="org88c60c1">Restoring the Session</h4>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<div class="org-src-container">

<pre class="prettyprint" data-lang="python">
saver = tf.train.Saver()
model_path = "./tmp/model.ckpt"
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  saver.restore(sess, model_path)
  print("Accuracy:", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))</pre>

</div>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org4b7ea9a" class="outline-3">
<h3 id="org4b7ea9a">Toy Program</h3>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<article class="flexbox vcenter">

<div class="figure">
<p><img src="images/toy_program.png" alt="toy_program.png" width="80%" />
</p>
</div>
</article>


</article>

</slide>

</slide>
</slide>
<slide id="sec-"  >
<hgroup class="">
       <h2 class=" "><div id="outline-container-org0b6c408" class="outline-2">
<h2 id="org0b6c408">References</h2>
</div>
</h2>
       <h3></h3>
       </hgroup>
<article class="" id="text-">
<ul>
<li><a href="https://github.com/PythonWorkshop/intro-to-tensorflow/blob/master/MathPrimer/Math%20primer%20for%20ML%20&amp;%20TensorFlow%20workshop.ipynb">Machine Learning Primer</a></li>
<li><a href="http://brohrer.github.io/how_convolutional_neural_networks_work.html">http://brohrer.github.io/how_convolutional_neural_networks_work.html</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a></li>
<li><a href="https://www.tensorflow.org/get_started/mnist/pros">https://www.tensorflow.org/get_started/mnist/pros</a></li>
<li><a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials">https://github.com/Hvass-Labs/TensorFlow-Tutorials</a></li>
</ul>


</article>

</slide>

</slide>
<slide id="sec-" class=" thank-you-slide segue nobackground" style="background-image: url(nil)">
<aside class="gdbar right"><img src="images/tensorflow.png"></aside><article class="flexbox vleft auto-fadein" id="text-">
<h2>
  <p>Thank You</p>
</h2>
<br>
<p class="auto-fadein" data-config-contact>
</p>
</article>

</slide>
<slide class="backdrop"></slide>
</slides> 
<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body> 

</html>
